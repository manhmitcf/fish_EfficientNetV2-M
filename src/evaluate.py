import argparse
import torch
from torch.utils.data import DataLoader
from dataset import FishDatasetWithAugmentation
from model import FishClassifier
import numpy as np
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from dataset import basic_transform

# ðŸ“Œ ThÃªm argparse Ä‘á»ƒ nháº­n tham sá»‘ tá»« command line
parser = argparse.ArgumentParser(description="Evaluate Fish Classifier")
parser.add_argument("--model_path", type=str, required=True, help="ÄÆ°á»ng dáº«n tá»›i file mÃ´ hÃ¬nh")
parser.add_argument("--csv_path", type=str, required=True, help="ÄÆ°á»ng dáº«n tá»›i file CSV cho dataset")
args = parser.parse_args()

# Load mÃ´ hÃ¬nh
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = FishClassifier().to(device)

try:
    model.load_state_dict(torch.load(args.model_path, map_location=device))
    model.eval()
except FileNotFoundError:
    raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file mÃ´ hÃ¬nh '{args.model_path}'.")

# Load test dataset
CSV_PATH = args.csv_path  # Äá»c CSV path tá»« dÃ²ng lá»‡nh
IMG_DIR = "data/images/"
IMG_DIR_AUG = "data/train_augmented/"  # ÄÆ°á»ng dáº«n tá»›i thÆ° má»¥c áº£nh Ä‘Ã£ tÄƒng cÆ°á»ng

try:
    dataset = FishDatasetWithAugmentation(CSV_PATH, IMG_DIR, IMG_DIR_AUG, transform=basic_transform)
    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)

except FileNotFoundError as e:
    raise FileNotFoundError(f"Lá»—i khi táº£i dataset: {e}")

all_preds, all_labels = [], []
with torch.no_grad():
    for images, labels in dataloader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)  # Outputs dáº¡ng xÃ¡c suáº¥t

        # Láº¥y lá»›p dá»± Ä‘oÃ¡n báº±ng cÃ¡ch chá»n chá»‰ sá»‘ cÃ³ xÃ¡c suáº¥t cao nháº¥t
        preds = torch.argmax(outputs, dim=1)

        all_preds.append(preds.cpu().numpy())
        all_labels.append(labels.cpu().numpy())

# Convert vá» numpy
all_preds = np.concatenate(all_preds)
all_labels = np.concatenate(all_labels)

# TÃ­nh accuracy vÃ  F1-score toÃ n bá»™ táº­p test
acc = accuracy_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds, average="macro")

print(f"Accuracy: {acc:.4f}")
print(f"F1-score: {f1:.4f}")

# BÃ¡o cÃ¡o chi tiáº¿t tá»«ng lá»›p
try:
    class_names = ["2.0", "3.0", "4.0", "5.0", "6.0", "7.0", "8.0", "9.0"]
    if len(set(all_labels)) > len(class_names):
        raise ValueError("Sá»‘ lÆ°á»£ng lá»›p thá»±c táº¿ lá»›n hÆ¡n sá»‘ lá»›p Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a.")
    class_report = classification_report(all_labels, all_preds, target_names=class_names)
    print("\nClassification Report:\n")
    print(class_report)
except ValueError as e:
    print(f"Lá»—i trong viá»‡c táº¡o bÃ¡o cÃ¡o lá»›p: {e}")

# TÃ­nh vÃ  hiá»ƒn thá»‹ Confusion Matrix
try:
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.show()
    plt.savefig("confusion_matrix.png")
except Exception as e:
    print(f"Lá»—i khi táº¡o Confusion Matrix: {e}")
