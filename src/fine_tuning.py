import argparse
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import transforms
from dataset import FishDatasetWithAugmentation
from model import FishClassifier 
import os
from tqdm import tqdm
from dataset import basic_transform, aug_transform
# üìå Th√™m argparse ƒë·ªÉ nh·∫≠n tham s·ªë t·ª´ terminal
parser = argparse.ArgumentParser(description="Train Fish Classifier")
parser.add_argument("--epochs", type=int, default=20, help="S·ªë epoch ƒë·ªÉ train (default: 20)")
parser.add_argument("--batch_size", type=int, default=32, help="Batch size (default: 32)")
parser.add_argument("--lr", type=float, default=0.001, help="Learning rate (default: 0.001)")
parser.add_argument("--model", type=str, default="models/fish_classifier.pth", help="T√™n file m√¥ h√¨nh (default: fish_classifier.pth)")
args = parser.parse_args()

# C·∫•u h√¨nh t·ª´ argparse
TRAIN_CSV_PATH = "data/train_balanced.csv"
VAL_CSV_PATH = "data/val.csv"
IMG_DIR = "data/images/"
IMG_DIR_AUG = "data/train_augmented/"
EPOCHS = args.epochs
BATCH_SIZE = args.batch_size
LEARNING_RATE = args.lr
NUM_CLASSES = 8


train_dataset = FishDatasetWithAugmentation(
    csv_file=TRAIN_CSV_PATH,
    img_dir=IMG_DIR,
    img_dir_aug=IMG_DIR_AUG,
    transform=None,
    aug_transform=aug_transform,  
)

val_dataset = FishDatasetWithAugmentation(
    csv_file=VAL_CSV_PATH,
    img_dir=IMG_DIR,
    img_dir_aug=IMG_DIR_AUG,
    transform=basic_transform,
)
train_dataloader = DataLoader(
    train_dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=True,   
)
val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# Load model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = FishClassifier(num_classes=NUM_CLASSES).to(device)
checkpoint_path = args.model  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file checkpoint
if not os.path.exists(checkpoint_path):
    raise FileNotFoundError(f"Checkpoint file {checkpoint_path} not found. Please check the path.")
checkpoint = torch.load(checkpoint_path, map_location=device)
# Load tr·ªçng s·ªë c≈© v√†o m√¥ h√¨nh
model.load_state_dict(checkpoint)
model.to(device)
# Loss v√† Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
loss_train = []
loss_val = []
acc_train = []
acc_val = []
# Training loop
for epoch in range(EPOCHS):
    # Training phase
    model.train()
    train_running_loss = 0.0
    train_correct = 0
    train_total = 0
    
    for images, labels in tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{EPOCHS} (Train)"):
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        train_running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()
    
    avg_train_loss = train_running_loss / len(train_dataloader)
    train_accuracy = 100 * train_correct / train_total
    
    # Validation phase
    model.eval()
    val_running_loss = 0.0
    val_correct = 0
    val_total = 0
    
    with torch.no_grad():
        for images, labels in val_dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()
    
    avg_val_loss = val_running_loss / len(val_dataloader)
    val_accuracy = 100 * val_correct / val_total
    
    loss_train.append(avg_train_loss)
    loss_val.append(avg_val_loss)
    acc_train.append(train_accuracy)
    acc_val.append(val_accuracy)
    print(f"    Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%")
    print(f"    Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%")

# L∆∞u m√¥ h√¨nh
os.makedirs("models", exist_ok=True)
torch.save(model.state_dict(), "models/fish_classifier_finetuned.pth")
print("ƒê√£ l∆∞u m√¥ h√¨nh!")



import matplotlib.pyplot as plt
import os

# T·∫°o th∆∞ m·ª•c "plots" n·∫øu ch∆∞a c√≥
os.makedirs("plots", exist_ok=True)

# V·∫Ω ƒë·ªì th·ªã loss v√† accuracy
plt.figure(figsize=(12, 6))

# ƒê·ªì th·ªã Loss
plt.subplot(1, 2, 1)  # Chia figure th√†nh 1 h√†ng, 2 c·ªôt, v·∫Ω ƒë·ªì th·ªã ƒë·∫ßu ti√™n ·ªü v·ªã tr√≠ 1
plt.plot(loss_train, label='Train Loss')
plt.plot(loss_val, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# ƒê·ªì th·ªã Accuracy
plt.subplot(1, 2, 2)  # Chia figure th√†nh 1 h√†ng, 2 c·ªôt, v·∫Ω ƒë·ªì th·ªã th·ª© hai ·ªü v·ªã tr√≠ 2
plt.plot(acc_train, label='Train Accuracy')
plt.plot(acc_val, label='Val Accuracy') 
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# S·∫Øp x·∫øp layout ƒë·ªÉ ƒë·ªì th·ªã kh√¥ng b·ªã ch·ªìng l√™n nhau
plt.tight_layout()

# L∆∞u ƒë·ªì th·ªã v√†o th∆∞ m·ª•c "plots"
plt.savefig("plots/loss_accuracy_plot_finetuned.png")  # L∆∞u ƒë·ªì th·ªã v√†o file PNG trong th∆∞ m·ª•c "plots"
print("ƒê√£ l∆∞u ƒë·ªì th·ªã accuracy v√† loss v√†o th∆∞ m·ª•c 'plots'!")

# Hi·ªÉn th·ªã ƒë·ªì th·ªã tr√™n m√†n h√¨nh
plt.show()

